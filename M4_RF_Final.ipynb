{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sugaminni/Quantum-Machine-Learning-Submission/blob/main/M4_RF_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIZyQp_DImJk"
      },
      "outputs": [],
      "source": [
        "# Ensure you have all the required libraries installed in Colab\n",
        "\n",
        "!pip install pennylane # Install the PennyLane library for quantum computing and machine learning\n",
        "!pip install matplotlib scikit-learn # Install matplotlib for data visualization and scikit-learn for machine learning algorithms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing PennyLane for quantum machine learning\n",
        "import pennylane as qml\n",
        "\n",
        "# Importing PennyLane's version of numpy for quantum-compatible operations\n",
        "from pennylane import numpy as np\n",
        "\n",
        "# Importing pandas for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Importing train_test_split to split the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing StandardScaler for feature scaling and LabelEncoder for encoding target labels\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Importing RandomForestClassifier for classification tasks\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Importing SelectFromModel to select important features based on the model\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Importing accuracy_score to calculate the accuracy of the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Importing matplotlib for data visualization\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "EKosSvXIIsbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Mounts Google Drive to access files stored in your drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Loads dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/BackOrders.csv', low_memory=False)\n",
        "\n",
        "# Defines the feature columns and target column\n",
        "features = ['national_inv', 'lead_time', 'in_transit_qty',\n",
        "            'forecast_3_month', 'forecast_6_month', 'sales_1_month']\n",
        "target = 'went_on_backorder'\n",
        "\n",
        "# Forces numeric features (fixes \"mixed types\" warning)\n",
        "for col in features:\n",
        "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
        "\n",
        "# Drops rows missing required fields (prevents scaler / quantum errors)\n",
        "data = data.dropna(subset=features + [target])\n",
        "\n",
        "# Selects features and target\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Encodes target labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Splits FIRST (prevents leakage); stratify keeps class ratio stable\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Scales using training stats only (prevents leakage)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "KDBx6-_RIsdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Random Forest classifier with 100 decision trees and a fixed random seed for reproducibility\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data using the trained Random Forest model\n",
        "rf_predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the Random Forest model on the test set\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "\n",
        "# Print the accuracy of the Random Forest model\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "LzmN2QwXIsgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a new Random Forest classifier for feature selection with 100 decision trees\n",
        "rf_selector = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest classifier on the training data to evaluate feature importance\n",
        "rf_selector.fit(X_train, y_train)\n",
        "\n",
        "# Select the top 3 most important features based on the Random Forest model\n",
        "# Using SelectFromModel with max_features set to 3 and threshold=-np.inf to select features regardless of their importance score\n",
        "selector = SelectFromModel(rf_selector, max_features=3, threshold=-np.inf)\n",
        "selector.fit(X_train, y_train)\n",
        "\n",
        "# Transform the training and test sets to include only the top 3 selected features\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_test_selected = selector.transform(X_test)"
      ],
      "metadata": {
        "id": "9xad6_DJIsip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a quantum device with 3 qubits using the default qubit simulator\n",
        "n_qubits = 3\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Define a quantum circuit using a qnode\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(inputs, weights):\n",
        "    # Encode the classical inputs as angles into the qubits\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "\n",
        "    # Apply a strongly entangling layer using the provided weights\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
        "\n",
        "    # Return the expectation values of the PauliZ operator for each qubit\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "# Define a hybrid model that sums up the quantum circuit's output\n",
        "def hybrid_model(inputs, weights):\n",
        "    return np.sum(quantum_circuit(inputs, weights))\n",
        "\n",
        "# Define the cost function to measure the difference between predictions and actual labels\n",
        "def cost(weights, features, labels):\n",
        "    predictions = np.array([hybrid_model(x, weights) for x in features])\n",
        "    return np.mean((predictions - labels)**2)"
      ],
      "metadata": {
        "id": "Q8WqofT2Iskq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize random weights for the quantum circuit with a seed for reproducibility\n",
        "np.random.seed(42)\n",
        "num_layers = 4  # Number of layers in the quantum circuit\n",
        "# Initialize random weights between -π/2 and π/2, shape corresponds to (num_layers, n_qubits, parameters per gate)\n",
        "weights_init = np.random.uniform(low=-np.pi/2, high=np.pi/2, size=(num_layers, n_qubits, 3), requires_grad=True)\n",
        "\n",
        "# Configure the Adam optimizer with a stepsize of 0.001\n",
        "opt = qml.AdamOptimizer(stepsize=0.001)\n",
        "\n",
        "# Set batch size and number of samples to use for training\n",
        "batch_size = 64\n",
        "num_train = 5000\n",
        "train_features = X_train_selected[:num_train]  # Select the first 5000 training samples\n",
        "train_labels = y_train[:num_train]\n",
        "\n",
        "# Initialize the weights for training\n",
        "weights = weights_init\n",
        "\n",
        "costs_val = []  # List to store the cost values during training\n",
        "\n",
        "# Train the quantum model for 100 optimization steps\n",
        "for i in range(100):  # Perform 100 steps of optimization\n",
        "    # Randomly select a batch of data for each step\n",
        "    batch_index = np.random.randint(0, len(train_features), (batch_size,))\n",
        "    X_batch = train_features[batch_index]\n",
        "    y_batch = train_labels[batch_index]\n",
        "\n",
        "    # Update the weights and calculate the cost for the current batch\n",
        "    weights, cost_val = opt.step_and_cost(lambda w: cost(w, X_batch, y_batch), weights)\n",
        "\n",
        "    # Append the cost value to the list\n",
        "    costs_val.append(cost_val)\n",
        "\n",
        "    # Print the cost every 10 steps\n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"Step {i + 1}, Cost: {cost_val:.4f}\")\n",
        "# Plot the training loss over time\n",
        "plt.plot(range(1, 101), costs_val)\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Training cost Over Time')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R1LcWHweIsnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make predictions using the trained hybrid quantum model\n",
        "def predict(X):\n",
        "    # Use the hybrid model to get predictions for each input in X\n",
        "    predictions = np.array([hybrid_model(x, weights) for x in X])\n",
        "\n",
        "    # Convert predictions to binary (0 or 1) using a threshold of 0.5\n",
        "    return (predictions > 0.5).astype(int)\n",
        "\n",
        "# Make predictions on the first 1000 test samples\n",
        "hybrid_predictions = predict(X_test_selected[:1000])  # Adjust the number of samples based on resources\n",
        "\n",
        "# Calculate the accuracy of the hybrid quantum model on the test set\n",
        "hybrid_accuracy = accuracy_score(y_test[:1000], hybrid_predictions)\n",
        "\n",
        "# Print the accuracy of the hybrid quantum model\n",
        "print(f\"Hybrid QML Accuracy: {hybrid_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "0WABZbW9Ispj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar chart to visualize accuracy comparison between Random Forest and Hybrid QML\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot bars with specified colors: orange for Random Forest and green for Hybrid QML\n",
        "plt.bar(['Random Forest', 'Hybrid QML'], [rf_accuracy, hybrid_accuracy], color=['orange', 'green'])\n",
        "\n",
        "# Set the title and labels for the plot\n",
        "plt.title('Model Accuracies')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)  # Set the y-axis limits from 0 to 1\n",
        "\n",
        "# Add the accuracy values on top of each bar for clarity\n",
        "for i, v in enumerate([rf_accuracy, hybrid_accuracy]):\n",
        "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AE-X1OlGIsry"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}